{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNA | Final Project | P2\n",
    "### Mohsen Ebadpour | 400131080 | m.ebadpour@aut.ac.ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mohsen/anaconda3/envs/pytorch/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix,accuracy_score\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch_geometric \n",
    "from torch_geometric.datasets import TUDataset\n",
    "from torch_geometric.loader import DataLoader\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric.nn import GCNConv,Linear,GATConv,GATv2Conv,SAGEConv, GATConv,ChebConv\n",
    "from torch.utils.data import random_split\n",
    "from torch_geometric.nn import GraphConv, TopKPooling\n",
    "from torch_geometric.nn import global_mean_pool as gap, global_max_pool as gmp\n",
    "from torch_geometric.nn.pool.topk_pool import topk,filter_adj\n",
    "LAYERS = {\n",
    "    GCNConv:\"GCNConv\",\n",
    "    GATConv: \"GATConv\",\n",
    "    SAGEConv:\"SAGEConv\",\n",
    "    ChebConv:\"ChebConv\"\n",
    "}\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Node`s Featrue</th>\n",
       "      <th>Edge`s Feature</th>\n",
       "      <th>Classes</th>\n",
       "      <th>No. graphs</th>\n",
       "      <th>Mean Edges No.</th>\n",
       "      <th>Mean Nodes No.</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>MUTAG</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>188</td>\n",
       "      <td>39.59</td>\n",
       "      <td>17.93</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Node`s Featrue  Edge`s Feature  Classes  No. graphs  Mean Edges No.  \\\n",
       "MUTAG               7               4        2         188           39.59   \n",
       "\n",
       "       Mean Nodes No.  \n",
       "MUTAG           17.93  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.manual_seed(777)\n",
    "def ReportDataset(name=\"ENZYMES\"):\n",
    "    _dataset = TUDataset(name=name,root=\"./{0}\".format(name))\n",
    "    data = {}\n",
    "    data[\"Node`s Featrue\"] = _dataset.num_node_features\n",
    "    data[\"Edge`s Feature\"] = _dataset.num_edge_features\n",
    "    data[\"Classes\"] = _dataset.num_classes\n",
    "    data[\"No. graphs\"] = len(_dataset)\n",
    "    #_dataset.transform = T.NormalizeFeatures()\n",
    "    \n",
    "    nodes,edges = 0,0\n",
    "    for dataset in _dataset:\n",
    "        nodes += dataset.num_nodes\n",
    "        edges += dataset.num_edges \n",
    "    \n",
    "    data[\"Mean Edges No.\"] = round(edges/len(_dataset),2)    \n",
    "    data[\"Mean Nodes No.\"] = round(nodes/len(_dataset),2)  \n",
    "    return data , _dataset\n",
    "    \n",
    "    \n",
    "name = \"MUTAG\"\n",
    "Names = [name]\n",
    "data,dataset = ReportDataset(name)\n",
    "pd.DataFrame([data]).set_axis(Names,axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GetSets(dataset,train=0.8,valid=0.1):\n",
    "    train_ratio = int(len(dataset)*train)\n",
    "    validation_ratio = int(len(dataset)*valid)\n",
    "    training_set,validation_set,test_set = random_split(dataset,[train_ratio , validation_ratio,len(dataset) - (train_ratio + validation_ratio)])\n",
    "    return training_set,validation_set,test_set\n",
    "\n",
    "TrainSet,ValidationSet,TestSet = GetSets(dataset,0.8,0.1)\n",
    "BatchSize = 128 \n",
    "TrainLoader = DataLoader(TrainSet, batch_size=BatchSize, shuffle=True)\n",
    "ValidationLoader = DataLoader(ValidationSet,batch_size=BatchSize,shuffle=False)\n",
    "TestLoader = DataLoader(TestSet,batch_size=1,shuffle=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def TestPerformance(model,loader):\n",
    "    model.eval()\n",
    "    correct = 0.\n",
    "    loss = 0.\n",
    "    for data in loader:\n",
    "        data = data.to(\"cuda\")\n",
    "        model = model.to(\"cuda\")\n",
    "        out = model(data)\n",
    "        pred = out.max(dim=1)[1]\n",
    "        correct += pred.eq(data.y).sum().item()\n",
    "        loss += F.cross_entropy(out,data.y).item()\n",
    "    return correct / len(loader.dataset),loss / len(loader.dataset)\n",
    "\n",
    "\n",
    "def Train(CLASS,args,TrainLoader,ValidationLoader,TestLoader,epoch:int,lr=0.01,\n",
    "          path=\"\",weight_decay=5e-4,show=True,dataset_name=\"MUTAG\",coment=\"\"):\n",
    "    device = \"cuda\"\n",
    "    \n",
    "    model = CLASS(**args)\n",
    "    model = model.to(device)\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    model.train()\n",
    "    loss_train = []\n",
    "    acc_train = []\n",
    "    \n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    \n",
    "    acc_test = []\n",
    "    \n",
    "    min_loss = 1e10\n",
    "    patience = 0\n",
    "    for ite in range(epoch):\n",
    "        model.train()\n",
    "        for i, data in enumerate(TrainLoader):\n",
    "            data = data.to(\"cuda\")\n",
    "            model = model.to(\"cuda\")\n",
    "            out = model(data)\n",
    "            loss = F.cross_entropy(out, data.y)\n",
    "            #print(\"Training loss:{}\".format(loss.item()))\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "            \n",
    "        val_acc,val_loss = TestPerformance(model,ValidationLoader)\n",
    "        train_acc,train_loss = TestPerformance(model,TrainLoader)\n",
    "        test_acc,test_loss = TestPerformance(model,TestLoader)\n",
    "        \n",
    "        acc_test.append(test_acc)\n",
    "        \n",
    "        acc_val.append(val_acc)\n",
    "        loss_val.append(val_acc)\n",
    "        \n",
    "        acc_train.append(train_acc)\n",
    "        loss_train.append(train_loss)\n",
    "        \n",
    "        if val_loss < min_loss:\n",
    "            torch.save(model.state_dict(),'latest.pth')\n",
    "            min_loss = val_loss\n",
    "            patience = 0\n",
    "        else:\n",
    "            patience += 1\n",
    "        if patience > 50:\n",
    "            break \n",
    "\n",
    "    model = CLASS(**args)\n",
    "    model.load_state_dict(torch.load('latest.pth'))\n",
    "    val_acc,val_loss = TestPerformance(model,ValidationLoader)\n",
    "    test_acc,test_loss = TestPerformance(model,TestLoader) \n",
    "    \n",
    "    \n",
    "    if show:  \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.figsize']= (14,5)\n",
    "        h,w = 1,2\n",
    "        plt.subplot(h,w,1)\n",
    "        plt.plot(loss_train,label=\"Train loss\")\n",
    "        plt.plot(loss_val,label=\"Validation loss\")\n",
    "        plt.title(\"Loss Report | {0} | {1}\".format(model.name,dataset_name))\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Cross Entropy Loss\")\n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        \n",
    "        plt.subplot(h,w,2)\n",
    "        plt.plot(acc_train,label=\"Train Accuracy\")\n",
    "        plt.plot(acc_val,label=\"Validation Accuracy\")\n",
    "        plt.title(\"Accuracy Report | Test Accuracy: {0}%\".format(round(test_acc*100,2)))\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"{3}/{1} | {0} | {2}.jpg\".format(model.name,dataset_name,coment,path))\n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    return round(test_acc*100,2)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGPool(torch.nn.Module):\n",
    "    def __init__(self,in_channels,ratio=0.5,non_linearity=torch.tanh,**karg):\n",
    "        super(SAGPool,self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.ratio = ratio\n",
    "        self.score_layer = karg[\"Conv\"](in_channels,**karg)\n",
    "        self.non_linearity = non_linearity\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_attr=None, batch=None):\n",
    "        if batch is None:\n",
    "            batch = edge_index.new_zeros(x.size(0))\n",
    "        score = self.score_layer(x,edge_index).squeeze()\n",
    "        perm = topk(score, self.ratio, batch)\n",
    "        \n",
    "        x = x[perm] * self.non_linearity(score[perm]).view(-1, 1)\n",
    "        batch = batch[perm]\n",
    "        edge_index, edge_attr = filter_adj(edge_index, edge_attr, perm, num_nodes=score.size(0))\n",
    "\n",
    "        return x, edge_index, edge_attr, batch, perm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SAGPoolNet(torch.nn.Module):\n",
    "    def __init__(self,dataset,is_hierarchical=True,pooling_ratio=0.5,p_dropout=0.5,hidden_features=128,use_w_for_concat=False,**karg):\n",
    "        super(SAGPoolNet, self).__init__()\n",
    "        from torch.nn.init import xavier_uniform_,zeros_\n",
    "        self.num_features = dataset.num_features\n",
    "        self.hidden_features = hidden_features\n",
    "        self.num_classes = dataset.num_classes\n",
    "        self.pooling_ratio = pooling_ratio\n",
    "        self.p = p_dropout\n",
    "        \n",
    "        global LAYERS\n",
    "        self.name = \"SAGPool | \"\n",
    "        self.name += \"Hierarchical | \" if is_hierarchical else \"Global | \"\n",
    "        self.name += \"Pooling ratio: {0} | \".format(str(pooling_ratio))\n",
    "        self.name += \"Weighted Concat | \" if use_w_for_concat else \"Simple Concat | \"\n",
    "        self.name += LAYERS[karg[\"Conv\"]]\n",
    "        \n",
    "        self.is_hierarchical = is_hierarchical\n",
    "        self.use_w_for_concat = use_w_for_concat\n",
    "        \n",
    "        if self.use_w_for_concat:\n",
    "            W = torch.Tensor(3,1)\n",
    "            W = nn.Parameter(W) \n",
    "            self._att = W\n",
    "            xavier_uniform_(self._att)\n",
    "            \n",
    "        if is_hierarchical:\n",
    "            self.lin1 = torch.nn.Linear(self.hidden_features*2, self.hidden_features)\n",
    "            self.conv1 = GCNConv(self.num_features, self.hidden_features)\n",
    "            self.pool1 = SAGPool(self.hidden_features, ratio=self.pooling_ratio,**karg)\n",
    "            self.conv2 = GCNConv(self.hidden_features, self.hidden_features)\n",
    "            self.pool2 = SAGPool(self.hidden_features, ratio=self.pooling_ratio,**karg)\n",
    "            self.conv3 = GCNConv(self.hidden_features, self.hidden_features)\n",
    "            self.pool3 = SAGPool(self.hidden_features, ratio=self.pooling_ratio,**karg)\n",
    "        else:\n",
    "            self.conv1 = GCNConv(self.num_features, self.hidden_features)\n",
    "            self.conv2 = GCNConv(self.hidden_features, self.hidden_features)\n",
    "            self.conv3 = GCNConv(self.hidden_features, self.hidden_features)\n",
    "            self.pool = SAGPool(self.hidden_features*3, ratio=self.pooling_ratio,**karg)\n",
    "            self.lin1 = torch.nn.Linear(self.hidden_features*2*3, self.hidden_features)\n",
    "            \n",
    "        self.lin2 = torch.nn.Linear(self.hidden_features, self.hidden_features//2)\n",
    "        self.lin3 = torch.nn.Linear(self.hidden_features//2, self. num_classes)\n",
    "\n",
    "    def forward(self, data):\n",
    "        if self.is_hierarchical:    \n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "\n",
    "            x = F.relu(self.conv1(x, edge_index))\n",
    "            x, edge_index, _, batch, _ = self.pool1(x, edge_index, None, batch)\n",
    "            x1 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "            x = F.relu(self.conv2(x, edge_index))\n",
    "            x, edge_index, _, batch, _ = self.pool2(x, edge_index, None, batch)\n",
    "            x2 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "            x = F.relu(self.conv3(x, edge_index))\n",
    "            x, edge_index, _, batch, _ = self.pool3(x, edge_index, None, batch)\n",
    "            x3 = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "            \n",
    "            if self.use_w_for_concat:\n",
    "                x = self._att[0][0]*x1 + self._att[1][0]*x2 + self._att[2][0]*x3\n",
    "            else:\n",
    "                x = x1 + x2 + x3\n",
    "            \n",
    "        else:\n",
    "            x, edge_index, batch = data.x, data.edge_index, data.batch\n",
    "            x1 = F.relu(self.conv1(x, edge_index)) \n",
    "            x2 = F.relu(self.conv2(x1, edge_index))\n",
    "            x3 = F.relu(self.conv3(x2, edge_index)) \n",
    "            \n",
    "            if self.use_w_for_concat:\n",
    "                x1 = self._att[0][0] * x1\n",
    "                x2 = self._att[1][0] * x2\n",
    "                x3 = self._att[2][0] * x3\n",
    "            \n",
    "            x = torch.concat([x1,x2,x3],dim=1)\n",
    "            x, edge_index, _, batch, _ = self.pool(x, edge_index, None, batch)\n",
    "            x = torch.cat([gmp(x, batch), gap(x, batch)], dim=1)\n",
    "\n",
    "        x = F.relu(self.lin1(x))\n",
    "        x = F.dropout(x, p=self.p, training=self.training)\n",
    "        x = F.relu(self.lin2(x))\n",
    "        x = F.log_softmax(self.lin3(x), dim=-1)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAINargs = {\n",
    "    \"dataset\":dataset,\n",
    "    \"out_channels\":1,\n",
    "    \"is_hierarchical\":True,\n",
    "    \"use_w_for_concat\":False,\n",
    "    \"pooling_ratio\":0.5,\n",
    "    \"p_dropout\":0.5,\n",
    "    \"Conv\":GCNConv\n",
    "    \n",
    "}\n",
    "\n",
    "\n",
    "def TrainModels(glo,args):\n",
    "    print(\"========\\n\")\n",
    "    CMD = \"\"\n",
    "    global LAYERS\n",
    "    for layer in LAYERS:\n",
    "        _args = args.copy()\n",
    "        _args[\"Conv\"] = layer \n",
    "        ACC = []\n",
    "        if \"H\" in glo:\n",
    "            _args[\"is_hierarchical\"] = True\n",
    "        else:\n",
    "            _args[\"is_hierarchical\"] = False\n",
    "            \n",
    "        if LAYERS[layer] == \"GATConv\":\n",
    "            _args[\"heads\"] = 6 \n",
    "            _args[\"concat\"] = False\n",
    "            \n",
    "        if LAYERS[layer] == \"ChebConv\":\n",
    "            _args[\"K\"] = 2\n",
    "        \n",
    "        path = \"./P2/\"\n",
    "        for index in tqdm(range(15)):\n",
    "            cmnt = str(index)\n",
    "            acc = Train(SAGPoolNet,_args,TrainLoader=TrainLoader,ValidationLoader=ValidationLoader,TestLoader=TestLoader,\n",
    "                epoch=500,lr=0.0005,weight_decay=0.0001,dataset_name=name,path=path,show=False,coment=cmnt)\n",
    "            ACC.append(acc)\n",
    "            \n",
    "        is_hie =  \"Hierarchical\"  if _args[\"is_hierarchical\"] else \"Global\" \n",
    "        cmd = \"Mean: {0}, STD:{1}, MIN:{4}, MAX:{5}, {2}, {3}\".format(round(np.mean(ACC),2),round(np.std(ACC),2),is_hie,LAYERS[layer],round(np.min(ACC),2),round(np.max(ACC),2))\n",
    "        print(cmd)\n",
    "        with open(path+\"{0} | is_hierarchical {1} | use_w_for_concat {2}.npy\".format(cmd,_args[\"is_hierarchical\"],_args[\"use_w_for_concat\"]),\"wb\") as f :\n",
    "            np.save(f,np.array(ACC))\n",
    "            \n",
    "        CMD += cmd + \"\\n\"\n",
    "    return CMD\n",
    "\n",
    "OUT = \"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [05:44<00:00, 23.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 72.0, STD:4.4, MIN:65.0, MAX:80.0, Hierarchical, GCNConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:45<00:00, 15.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 70.67, STD:3.59, MIN:65.0, MAX:80.0, Hierarchical, GATConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [04:52<00:00, 19.47s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 73.33, STD:5.06, MIN:70.0, MAX:85.0, Hierarchical, SAGEConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [05:43<00:00, 22.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 73.33, STD:2.98, MIN:70.0, MAX:80.0, Hierarchical, ChebConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT += TrainModels(\"H\",MAINargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:24<00:00, 13.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 73.67, STD:5.62, MIN:65.0, MAX:80.0, Global, GCNConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:32<00:00, 14.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 72.67, STD:6.02, MIN:65.0, MAX:80.0, Global, GATConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [02:41<00:00, 10.77s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 74.0, STD:5.54, MIN:65.0, MAX:80.0, Global, SAGEConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:47<00:00, 15.18s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 74.33, STD:4.78, MIN:65.0, MAX:80.0, Global, ChebConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT += TrainModels(\"G\",MAINargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [05:59<00:00, 23.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 71.67, STD:5.06, MIN:65.0, MAX:85.0, Hierarchical, GCNConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [04:48<00:00, 19.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 71.0, STD:2.0, MIN:70.0, MAX:75.0, Hierarchical, GATConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [04:52<00:00, 19.50s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 71.33, STD:3.4, MIN:65.0, MAX:80.0, Hierarchical, SAGEConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [05:24<00:00, 21.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 70.0, STD:3.16, MIN:65.0, MAX:75.0, Hierarchical, ChebConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "tmp = MAINargs.copy()\n",
    "tmp[\"use_w_for_concat\"] = True\n",
    "OUT += TrainModels(\"H\",tmp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:28<00:00, 13.90s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 72.33, STD:4.78, MIN:65.0, MAX:80.0, Global, GCNConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:46<00:00, 15.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 70.0, STD:3.16, MIN:65.0, MAX:75.0, Global, GATConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:08<00:00, 12.58s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 71.33, STD:4.99, MIN:65.0, MAX:80.0, Global, SAGEConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 15/15 [03:48<00:00, 15.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean: 70.67, STD:5.12, MIN:65.0, MAX:80.0, Global, ChebConv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "OUT += TrainModels(\"G\",tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b560098fd368adebc083c1b4880b937d75f58d5ed55fd9229240453cbfc389ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
