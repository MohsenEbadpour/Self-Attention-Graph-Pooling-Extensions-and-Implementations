{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNA | Final Project | P1\n",
    "### Mohsen Ebadpour | 400131080 | m.ebadpour@aut.ac.ir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch import nn\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torch.nn import functional as F\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd \n",
    "from sklearn.metrics import confusion_matrix\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "import torch_geometric \n",
    "from torch_geometric.datasets import Planetoid,DBLP,CoraFull\n",
    "from torch_geometric import transforms as T\n",
    "from torch_geometric.nn import GCNConv,Linear,GATConv,GATv2Conv\n",
    "\n",
    "from torch_geometric.nn.conv import MessagePassing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Report Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def ReportDataset(name=\"PubMed\"):\n",
    "    if name == \"CoraFull\":\n",
    "        _dataset = CoraFull(\"./{0}\".format(name))\n",
    "    else:\n",
    "        _dataset = Planetoid(name=name,root=\"./{0}\".format(name))\n",
    "    data = {}\n",
    "    data[\"Node`s Featrue\"] = _dataset.num_node_features\n",
    "    data[\"Edge`s Feature\"] = _dataset.num_edge_features\n",
    "    data[\"Classes\"] = _dataset.num_classes\n",
    "    data[\"Nodes\"] = _dataset[0].num_nodes\n",
    "    data[\"Edges\"] = _dataset[0].num_edges\n",
    "    if name == \"CoraFull\":\n",
    "        data[\"Train Nodes\"] = np.nan\n",
    "        data[\"Test Nodes\"] = np.nan\n",
    "        data[\"Validation Nodes\"] = np.nan\n",
    "        return data\n",
    "    \n",
    "    data[\"Train Nodes\"] = _dataset[0].x[_dataset[0].train_mask].shape[0]\n",
    "    data[\"Test Nodes\"] = _dataset[0].x[_dataset[0].test_mask].shape[0]\n",
    "    data[\"Validation Nodes\"] = _dataset[0].x[_dataset[0].val_mask].shape[0]\n",
    "    return data\n",
    "    \n",
    "    \n",
    "info = []\n",
    "Names = [\"Cora\",\"CiteSeer\",\"PubMed\",\"CoraFull\"]\n",
    "for name in Names:\n",
    "    info.append(ReportDataset(name))\n",
    "    \n",
    "pd.DataFrame(info).set_axis(Names,axis=0)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def GetDataset(name=\"Cora\"):\n",
    "    _transform = T.Compose([T.RandomNodeSplit()])\n",
    "    _transform(CoraFull(\"./CoraFull\")[0])\n",
    "    if name == \"CoraFull\":\n",
    "        _dataset = CoraFull(\"./{0}\".format(name))\n",
    "        _dataset = _transform(_dataset[0])\n",
    "        \n",
    "    else:\n",
    "        _dataset = Planetoid(name=name,root=\"./{0}\".format(name))[0]\n",
    "        \n",
    "    return _dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "def Train(model,dataset,epach:int,lr=0.01, weight_decay=5e-4,show=True,dataset_name=\"Cora\",loss_f=\"nll\",coment=\"\"):\n",
    "    device = \"cuda\"\n",
    "    model = model.to(device)\n",
    "    dataset = dataset.to(device)\n",
    "    LOSE = F.nll_loss if loss_f==\"nll\" else F.cross_entropy\n",
    "    opt = optim.Adam(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    \n",
    "    \n",
    "    model.train()\n",
    "    losses_train = []\n",
    "    acc_train = []\n",
    "    \n",
    "    loss_val = []\n",
    "    acc_val = []\n",
    "    acc_test = []\n",
    "    \n",
    "    for ite in range(epach):\n",
    "        model.train()\n",
    "        opt.zero_grad()\n",
    "        out = model(dataset)\n",
    "        loss = LOSE(out[dataset.train_mask],dataset.y[dataset.train_mask])\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        \n",
    "        model.eval()\n",
    "        losses_train.append(loss.item())\n",
    "        \n",
    "        loss_valid = LOSE(out[dataset.val_mask],dataset.y[dataset.val_mask])\n",
    "        loss_val.append(loss_valid.item())\n",
    "        \n",
    "        pred = model(dataset).argmax(dim=1)\n",
    "        correct = (pred[dataset.train_mask] == dataset.y[dataset.train_mask]).sum()\n",
    "        acc_t = float(correct) / float(dataset.train_mask.sum())\n",
    "        acc_train.append(acc_t)\n",
    "        \n",
    "        \n",
    "        pred = model(dataset).argmax(dim=1)\n",
    "        correct = (pred[dataset.test_mask] == dataset.y[dataset.test_mask]).sum()\n",
    "        acc = float(correct) / float(dataset.test_mask.sum())\n",
    "        acc_test.append(acc)\n",
    "        \n",
    "        pred = model(dataset).argmax(dim=1)\n",
    "        correct = (pred[dataset.val_mask] == dataset.y[dataset.val_mask]).sum()\n",
    "        acc_ = float(correct) / float(dataset.val_mask.sum())\n",
    "        acc_val.append(acc_)\n",
    "        \n",
    "    model = model.to(\"cpu\")\n",
    "    dataset = dataset.to(\"cpu\")\n",
    "    pred = model(dataset).argmax(dim=1)\n",
    "    correct = (pred[dataset.test_mask] == dataset.y[dataset.test_mask]).sum()\n",
    "    acc = float(correct) / float(dataset.test_mask.sum())\n",
    "\n",
    "    if show:  \n",
    "        sns.set_style(\"whitegrid\")\n",
    "        plt.rcParams['figure.figsize']= (10,10)\n",
    "        h,w = 2,2\n",
    "        plt.subplot(h,w,1)\n",
    "        plt.plot(losses_train,label=\"Train loss\")\n",
    "        plt.plot(loss_val,label=\"Validation loss\")\n",
    "        plt.title(\"Loss Report | {0} | {1}\".format(model.name,dataset_name))\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.ylabel(\"Cross Entropy Loss\")\n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "        \n",
    "        plt.subplot(h,w,2)\n",
    "        plt.plot(acc_train,label=\"Train Accuracy\")\n",
    "        plt.plot(acc_val,label=\"Validation Accuracy\")\n",
    "        plt.title(\"Accuracy Report\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        #plt.show()\n",
    "    \n",
    "        \n",
    "        plt.subplot(h,w,3)\n",
    "        cm = confusion_matrix(np.array(dataset.y[dataset.test_mask]),np.array(pred[dataset.test_mask]))\n",
    "        sns.heatmap(cm,cmap=\"Blues\",annot=True,cbar=False,fmt=\"g\")\n",
    "        plt.title(\"Confusion Matrix for TEST data | Accuracy:{0}%\".format(round(acc*100,2)))\n",
    "        plt.ylabel(\"Predicted Label\")\n",
    "        plt.xlabel(\"True Label\")\n",
    "        \n",
    "        plt.subplot(h,w,4)\n",
    "        plt.plot(acc_test,label=\"Test Accuracy\",color=\"green\")\n",
    "        plt.title(\"Test accuracy report during train\")\n",
    "        plt.xlabel(\"Epoch\")\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(\"./P1/{1} | {0} | {2}\".format(model.name,dataset_name,coment))\n",
    "        #plt.show()\n",
    "        plt.clf()\n",
    "        \n",
    "    return acc,acc_,acc_t\n",
    "    \n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net-GCN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NetGCN(torch.nn.Module):\n",
    "    def __init__(self,num_layer=2,data_set=None,linear=None,p=0.6,Linears = [16,32,64,128,256,512],dim=[15]):\n",
    "        super().__init__()\n",
    "        \n",
    "        if linear is not None:\n",
    "            num_layer += 1\n",
    "         \n",
    "           \n",
    "        self.convs = nn.ModuleList()\n",
    "        self.p =p\n",
    "        n_calsss = torch.unique(data_set.y).shape[0]\n",
    "        n_feaute_in =  data_set.x.shape[1]\n",
    "        self.name = \"GCN-NET | Con:\" +str(n_feaute_in) \n",
    "        dim = [n_feaute_in] + dim + [n_calsss]\n",
    "\n",
    "        step = 1 if linear is not None else 0\n",
    "        for i in range(0,len(dim)-1-step):\n",
    "            conv = GCNConv(dim[i],dim[i+1])\n",
    "            self.name += \" -> \"+str(dim[i+1])\n",
    "            self.convs.append(conv)\n",
    "            \n",
    "        self.use_linear = False   \n",
    "        if linear:    \n",
    "            self.linears = nn.ModuleList()\n",
    "            self.use_linear = True \n",
    "            Linears = Linears[0:linear-1]\n",
    "            #Linears.reverse()\n",
    "            Linears.insert(0,dim[-2])\n",
    "            #Linears.reverse()\n",
    "            Linears.append(n_calsss)\n",
    "            self.name += \" | CLF: \"  + str(Linears[0])\n",
    "            for i in range(1,len(Linears)):\n",
    "                lin = Linear(Linears[i-1],Linears[i])\n",
    "                self.linears.append(lin)\n",
    "                self.name += \" -> \"+str(Linears[i])\n",
    "            \n",
    "    def forward(self,dataset):\n",
    "        x_in,edge_index = dataset.x,dataset.edge_index\n",
    "        \n",
    "        \n",
    "        for index in range(len(self.convs)-1):\n",
    "            x_in = self.convs[index](x_in,edge_index)\n",
    "            x_in = F.relu(x_in)\n",
    "            x_in = F.dropout(x_in,training=self.training,p=self.p)\n",
    "            \n",
    "        if not self.use_linear:    \n",
    "            x = self.convs[-1](x_in,edge_index)\n",
    "            Y = F.log_softmax(x,dim=1)\n",
    "            return Y\n",
    "            \n",
    "        x_in = self.convs[-1](x_in,edge_index)\n",
    "        \n",
    "        for index in range(len(self.linears)-1):\n",
    "            x_in = self.linears[index](x_in)\n",
    "            x_in = F.relu(x_in)\n",
    "            x_in = F.dropout(x_in,training=self.training,p=self.p)\n",
    "            \n",
    "        x = self.linears[-1](x_in)\n",
    "        Y = F.softmax(x,dim=1)\n",
    "        return Y\n",
    "            \n",
    "\n",
    "\n",
    "name = \"PubMed\"\n",
    "dataset = GetDataset(name)\n",
    "\n",
    "TestConvLayers = [\n",
    "    [16],[16,16],[16,16,16],[16,16,16,16],\n",
    "    [16,32],[32,16],[32,32],[24,16],[16,24],[64,128],[128,64]\n",
    "]\n",
    "\n",
    "TestFullyLayer = [None,1,2,3,4]\n",
    "Linears = [64,32,16,8]\n",
    "\n",
    "NumLayers = []\n",
    "TrainAcc = []\n",
    "TestAcc = []\n",
    "ValidAcc = []\n",
    "LayersN = []\n",
    "\n",
    "LenFLayer = []\n",
    "layersF = []\n",
    "\n",
    "for conv_layer in tqdm(TestConvLayers):\n",
    "    for full_layer in tqdm(TestFullyLayer):\n",
    "        if full_layer is not None:\n",
    "            Linears_test = Linears[-full_layer:]\n",
    "            LenFLayer.append(full_layer)\n",
    "            layersF.append(Linears_test.copy())\n",
    "            lo = \"cross\"\n",
    "            \n",
    "        else:\n",
    "            Linears_test = np.nan  \n",
    "            LenFLayer.append(np.nan)\n",
    "            layersF.append(np.nan)\n",
    "            lo = \"nll\"\n",
    "            \n",
    "        model = NetGCN(len(conv_layer),data_set=dataset,p=0.4,linear=full_layer,dim=conv_layer,Linears=Linears_test)\n",
    "        te,va,tr = Train(model=model,dataset=dataset,epach=1000,dataset_name=name,loss_f=lo,lr=0.0003,weight_decay=5e-4,coment=\"GCN Search\")\n",
    "        te,va,tr = round(te*100,2),round(va*100,2),round(tr*100,2)\n",
    "        TrainAcc.append(tr)\n",
    "        TestAcc.append(te)\n",
    "        ValidAcc.append(va)\n",
    "        NumLayers.append(len(conv_layer))\n",
    "        LayersN.append(conv_layer.copy())\n",
    "        \n",
    "\n",
    "Total = [ NumLayers,LayersN,TrainAcc,ValidAcc,TestAcc, LenFLayer,layersF]\n",
    "labels = [\"No. GCNs\",\"GCNs\",\"Train Acc\",\"Validation Acc\",\"Test Acc\",\"No. FCs\",\"FCs\"]\n",
    "gcn_search = pd.DataFrame(Total).T.set_axis(labels=labels,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "gcn_search.to_excel(\"./results.xlsx\",index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom-Layer-GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLayerGAT(GATConv):\n",
    "    def __init__(self, in_channels, out_channels: int, heads: int = 1, concat: bool = True, negative_slope: float = 0.2,is_weighted=False, dropout: float = 0, add_self_loops: bool = True, edge_dim = None, fill_value = 'mean', bias: bool = True, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, heads, concat, negative_slope, dropout, add_self_loops, edge_dim, fill_value, bias, **kwargs)\n",
    "        \n",
    "        from torch.nn.init import xavier_uniform_,zeros_\n",
    "        if is_weighted and concat:\n",
    "            W = torch.Tensor(heads,1)\n",
    "            W = nn.Parameter(W) \n",
    "            self._weight_heads = W\n",
    "            xavier_uniform_(self._weight_heads)       \n",
    "        \n",
    "        if is_weighted and concat:\n",
    "            self.bias = nn.Parameter(torch.Tensor(out_channels))\n",
    "        \n",
    "        zeros_(self.bias)\n",
    "        self.is_weighted = is_weighted\n",
    "        \n",
    "    def forward(self, x, edge_index, edge_attr = None, size = None, return_attention_weights = None):\n",
    "        H, C = self.heads, self.out_channels\n",
    "        if isinstance(x, torch.Tensor):\n",
    "            assert x.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
    "            x_src = x_dst = self.lin_src(x).view(-1, H, C)\n",
    "        else:  \n",
    "            x_src, x_dst = x\n",
    "            assert x_src.dim() == 2, \"Static graphs not supported in 'GATConv'\"\n",
    "            x_src = self.lin_src(x_src).view(-1, H, C)\n",
    "            if x_dst is not None:\n",
    "                x_dst = self.lin_dst(x_dst).view(-1, H, C)\n",
    "\n",
    "        x = (x_src, x_dst)\n",
    "\n",
    "        alpha_src = (x_src * self.att_src).sum(dim=-1)\n",
    "        alpha_dst = None if x_dst is None else (x_dst * self.att_dst).sum(-1)\n",
    "        alpha = (alpha_src, alpha_dst)\n",
    "\n",
    "        if self.add_self_loops:\n",
    "            from torch_geometric.utils import add_self_loops, remove_self_loops, softmax\n",
    "            from torch_geometric.typing import (Adj,OptPairTensor,OptTensor,Size,SparseTensor,)\n",
    "            import torch_sparse\n",
    "            if isinstance(edge_index, torch.Tensor):\n",
    "\n",
    "                num_nodes = x_src.size(0)\n",
    "                if x_dst is not None:\n",
    "                    num_nodes = min(num_nodes, x_dst.size(0))\n",
    "                num_nodes = min(size) if size is not None else num_nodes\n",
    "                edge_index, edge_attr = remove_self_loops(\n",
    "                    edge_index, edge_attr)\n",
    "                edge_index, edge_attr = add_self_loops(\n",
    "                    edge_index, edge_attr, fill_value=self.fill_value,\n",
    "                    num_nodes=num_nodes)\n",
    "            elif isinstance(edge_index, SparseTensor):\n",
    "                if self.edge_dim is None:\n",
    "                    edge_index = torch_sparse.set_diag(edge_index)\n",
    "                else:\n",
    "                    raise NotImplementedError(\n",
    "                        \"The usage of 'edge_attr' and 'add_self_loops' \"\n",
    "                        \"simultaneously is currently not yet supported for \"\n",
    "                        \"'edge_index' in a 'SparseTensor' form\")\n",
    "        alpha = self.edge_updater(edge_index, alpha=alpha, edge_attr=edge_attr)\n",
    "        out = self.propagate(edge_index, x=x, alpha=alpha, size=size)\n",
    "\n",
    "        if self.concat:\n",
    "            if self.is_weighted:\n",
    "                out = torch.transpose(out,1,2)\n",
    "                out = (out@self._weight_heads).squeeze(dim=2)\n",
    "            else:\n",
    "                out = out.view(-1, self.heads * self.out_channels)\n",
    "        else:\n",
    "            out = out.mean(dim=1)\n",
    "\n",
    "        if self.bias is not None:\n",
    "            out = out + self.bias\n",
    "        return out    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net-GAT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NetGAT(torch.nn.Module):\n",
    "    def __init__(self,heads=1,hidden_features=64,dataset=None,is_concat=True,linear_dim=32,is_weighted=False,p=0.6):\n",
    "        super().__init__()\n",
    "        n_calsss = torch.unique(dataset.y).shape[0]\n",
    "        n_feaute_in =  dataset.x.shape[1]\n",
    "        \n",
    "        if is_concat:\n",
    "            if is_weighted:\n",
    "                hidden_out = hidden_features\n",
    "            else:\n",
    "                hidden_out = hidden_features*heads\n",
    "                \n",
    "        else:\n",
    "            hidden_out = hidden_features\n",
    "            \n",
    "        #print(n_feaute_in,hidden_out,hidden_features,heads)\n",
    "        self.is_concat = is_concat\n",
    "        self.hidden_features = hidden_features\n",
    "        self.heads = heads\n",
    "        self.p = p\n",
    "        \n",
    "        self.name= \"GAT-Net | \"\n",
    "        self.name += \"Head: \"+ str(heads) +\" | \"\n",
    "        self.name += \"Weighted\" if is_weighted else \"Mean\"\n",
    "        \n",
    "        \n",
    "        self.is_wieghted = is_weighted\n",
    "        self.show = True\n",
    "        self.gat_layer_1 = CustomLayerGAT(n_feaute_in,n_calsss,heads,concat=is_concat,is_weighted=is_weighted,dropout=p)\n",
    "        self.gat_layer_2 = CustomLayerGAT(hidden_out,n_calsss,1,concat=False,is_weighted=False,dropout=p)\n",
    "        \n",
    "            \n",
    "    def forward(self,dataset):\n",
    "        x_in,edge_index = dataset.x,dataset.edge_index\n",
    "        x_in = self.gat_layer_1(x_in,edge_index)\n",
    "\n",
    "        x_in = F.dropout(x_in,training=self.training,p=self.p)\n",
    "        x_in = F.elu(x_in)\n",
    "        x_in = self.gat_layer_2(x_in,edge_index)\n",
    "        Y = F.log_softmax(x_in,dim=1)\n",
    "        return Y   \n",
    "\n",
    "def plot_10_head_chart(head=11,dataset=None,p=0.6):\n",
    "    accuracy = []\n",
    "    valid = []\n",
    "    for i in tqdm(range(1,head)):\n",
    "        model = NetGAT(heads=i,hidden_features=16,dataset=dataset,is_concat=False,is_weighted=False,p=p)\n",
    "        a,v,t = Train(model=model,dataset=dataset,epach=1500,dataset_name=name,show=True,loss_f=\"cross\",lr=0.0003,weight_decay=5e-3,coment=\"Heads:\".format(i))\n",
    "        accuracy.append(a)\n",
    "        valid.append(v)\n",
    "        #print(a)\n",
    "        \n",
    "    plt.rcParams['figure.figsize']= (5,5)\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    plt.plot(list(range(1,head)),accuracy,label=\"Test accuracy\",color=\"red\")\n",
    "    plt.title(\"Heads count report | Best: {0} - {1}%\".format(np.argmax(accuracy)+1,round(100*max(accuracy),4)))\n",
    "    plt.xlabel(\"Heads No.\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.xticks(list(range(1,head)))\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    return np.argmax(accuracy)+1,accuracy\n",
    "    \n",
    "    \n",
    "p = 0.6\n",
    "best_head,accs = plot_10_head_chart(11,dataset=dataset,p=p)\n",
    "model = NetGAT(heads=best_head,hidden_features=16,dataset=dataset,is_concat=True,is_weighted=True,p=p)\n",
    "a,v,t = Train(model=model,dataset=dataset,epach=1500,dataset_name=name,show=True,loss_f=\"cross\",lr=0.0003,weight_decay=5e-3,coment=\"Best Weighted Head\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom GAT-v2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class CustomLayerGATv2(GATv2Conv):\n",
    "    def __init__(self, in_channels, out_channels: int, heads: int = 1, concat: bool = True, negative_slope: float = 0.2, \n",
    "                dropout: float = 0, add_self_loops: bool = True, edge_dim = None, fill_value = 'mean', bias: bool = True, \n",
    "                share_weights: bool = False, **kwargs):\n",
    "        super().__init__(in_channels, out_channels, heads, concat, negative_slope, dropout, add_self_loops, edge_dim, fill_value, bias, share_weights, **kwargs)\n",
    "        if \"aggregation_type\" in kwargs:\n",
    "            self.aggregation_type = kwargs[\"aggregation_type\"]\n",
    "        else:\n",
    "            raise ValueError(\"Aggregation Type not passed\")\n",
    "\n",
    "    def CustomOperation(self,h_i,h_j):\n",
    "        if self.aggregation_type == \"min\":\n",
    "            return torch.min(h_i,h_j)\n",
    "        elif self.aggregation_type == \"max\":\n",
    "            return torch.max(h_i,h_j)\n",
    "        elif self.aggregation_type == \"hadamard\":\n",
    "            return torch.multiply(h_i,h_j)\n",
    "        elif self.aggregation_type == \"concat\":\n",
    "            return h_i + h_j\n",
    "\n",
    "    def message(self, x_j, x_i, edge_attr, index, ptr, size_i):\n",
    "        from torch_geometric.utils import softmax\n",
    "        x = self.CustomOperation(x_i,x_j)\n",
    "\n",
    "        if edge_attr is not None:\n",
    "            if edge_attr.dim() == 1:\n",
    "                edge_attr = edge_attr.view(-1, 1)\n",
    "            assert self.lin_edge is not None\n",
    "            edge_attr = self.lin_edge(edge_attr)\n",
    "            edge_attr = edge_attr.view(-1, self.heads, self.out_channels)\n",
    "            x = x + edge_attr\n",
    "\n",
    "        x = F.leaky_relu(x, self.negative_slope)\n",
    "        alpha = (x * self.att).sum(dim=-1)\n",
    "        alpha = softmax(alpha, index, ptr, size_i)\n",
    "        self._alpha = alpha\n",
    "        alpha = F.dropout(alpha, p=self.dropout, training=self.training)\n",
    "        return x_j * alpha.unsqueeze(-1)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Net-GATv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": [
    "class NetGATv2(torch.nn.Module):\n",
    "    def __init__(self,heads=1,hidden_features=32,dataset=None,p=0.6,aggregation_type=\"max\"):\n",
    "        super().__init__()\n",
    "        n_calsss = torch.unique(dataset.y).shape[0]\n",
    "        n_feaute_in =  dataset.x.shape[1]\n",
    "        \n",
    "        self.p = p \n",
    "        self.gat_1 = CustomLayerGATv2(in_channels=n_feaute_in,out_channels=hidden_features,heads=heads,concat=False,aggregation_type=aggregation_type,share_weights=True)\n",
    "        self.gat_2 = CustomLayerGATv2(in_channels=hidden_features,out_channels=n_calsss,heads=heads,concat=False,aggregation_type=aggregation_type,share_weights=True)\n",
    "        self.name = \"GATv2 | Opreation:\" + aggregation_type \n",
    "    def forward(self,dataset):\n",
    "        x_in,edge_index = dataset.x,dataset.edge_index\n",
    "        x_in = self.gat_1(x_in,edge_index)\n",
    "        x_in = F.dropout(x_in,training=self.training,p=self.p)\n",
    "        x_in = F.elu(x_in)\n",
    "        x_in = self.gat_2(x_in,edge_index)\n",
    "        Y = F.log_softmax(x_in,dim=1)\n",
    "        return Y\n",
    "   \n",
    "\n",
    "for aggr_type in tqdm([\"min\",\"max\",\"hadamard\",\"concat\"]):\n",
    "    model = NetGATv2(heads=2,hidden_features=32,dataset=dataset,aggregation_type=aggr_type)\n",
    "    a,v,t = Train(model=model,dataset=dataset,epach=2000,dataset_name=name,show=True,loss_f=\"cross\",lr=0.0002,weight_decay=5e-3,coment=\"Aggregation type\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "python"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b560098fd368adebc083c1b4880b937d75f58d5ed55fd9229240453cbfc389ac"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
